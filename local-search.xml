<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>计算机网络知识复习</title>
    <link href="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/"/>
    <url>/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p><strong>HTTP 1.0 和 2.0 有什么区别?</strong></p><p>HTTP&#x2F;1.0 版本主要增加以下几点:<br>1.增加了 HEAD、POST 等新方法。<br>2.增加了响应状态码。<br>3.引入了头部，即请求头和响应头。<br>4.在请求中加入了 HTTP 版本号。<br>5.引入了 Content-Type ，使得传输的数据不再限于文本。</p><p>HTTP&#x2F;1.1 版本主要增加以下几点:<br>1.新增了连接管理即 keepalive ，允许持久连接。<br>2.支持 pipeline，无需等待前面的请求响应，即可发送第二次请求。<br>3.允许响应数据分块(chunked)，即响应的时候不标明Content-Length，客户端就无法断开连接，直到收到服务端的 EOF，利于传输大文件。<br>4.新增缓存的控制和管理。<br>5.加入了 Host 头，用在你一台机子部署了多个主机，然后多个域名解析又是同一个IP，此时加入了 Host 头就可以判断你到底是要访问哪个主机。</p><p>HTTP&#x2F;2 版本主要增加以下几点:<br>1.是二进制协议，不再是纯文本上<br>2.支持一个TCP 连接发起多请求，移除了pipeline。<br>3.利用 HPACK 压缩头部，减少数据传输量。<br>4.允许服务端主动推送数据。</p><p><strong>HTTP 2.0 和 3.0 有什么区别?</strong></p><p>痛点来自于 HTTP 依赖的 TCP。TCP 是面向可靠的、有序的传输协议，因此会有失败重传和按序机制，而 HTTP&#x2F;2 是所有流共享一个 TCP 连接所以会有 TCP 层面的队头阻塞，当发生重传时会影响多个请求响应。<br>并且 TCP 是基于四元组(源IP，源端口，目标IP，目标端口)来确定连接的，而在移动网络的情况下IP 地址会频繁的换，这会导致反复的建连。<br>还有 TCP 与 TLS 的叠加握手，增加了延时。<br>问题就出在 TCP 身上，所以 Google 就把目光瞄向了 UDP。<br> QUIC 引入了个叫 Connection ID 来标识一个链接，所以切换网络之后可以复用这个连接，达到0RTT 就能开始传输。</p><p> HTTP&#x2F;2 提到的 HPACK，这个是依赖 TCP 的可靠、有序传输的，于是 QUC 得搞了个 QPACK，也采用了静态表、动态表和哈夫曼编码。<br>它丰富了 HTTP&#x2F;2 的静态表，从 61 项加到了 98 项。<br>上面提到的动态表，是用来存储末包含在静态表中的头部项，假设动态表还未收到，后面来解头部的时候肯定要被阻塞的。所以 QPACK 就另开一条路，在单向的 Stream 里传输动态表的编解码，单向传输好了，接受端到才能开始解码也就是说还没好你就先别管，防止做一半卡住了。<br>**那还有前面提到的 TCP 队头阻塞， QUIC 是怎么解决的呢?**毕竟它也要保证有序和可靠啊。<br>因为 TCP 不认识每个流分别是哪个请求的，所以它只能全部阻塞住，而 QUIC 知道，因此比如请求 A 丢包了我就把 A卡住了就行，请求 B完全可以全部放行，丝毫不受影响。<br>可以看到基于 UDP 的 QUIC 还是很强大的，而且人家用户多，在 2018 年，互联网标准化组织IETF 提议将 HTTPover QUIc 更名为 HTTP&#x2F;3 并获得批准。</p><p><strong>HTTP 和 HTTPS 有什么区别?</strong></p><p>http 是明文传输，而 https 是加密传输，所以基本上市面上的网站用的都是 htps 协议，因为明文传输很容易被中间人抓包然后获取一些敏感信息。<br>而加密传输中间人只能获取加密的数据<br>https 是基于http上又加了SSL(Secure Sockets Layer)或TLS(Transport Layer Security)协议来实现的加密传输。<br>https 传输的过程使用对称加密，这比非对称加密更加高效。</p><p>端口不一样，http是80，https是443。 https相较于http在三次握手之后还需要进行SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。</p><p><strong>TCP 是用来解决什么问题?</strong></p><p>TCP 即 Transmission Control Protocol，可以看到是一个传输控制协议，<br>控制可靠、按序地传输以及端与端之间的流量控制。拥塞控制，需要为整体网络的情况考虑。</p><p><strong>TCP 和 UDP 有什么区别?</strong></p><p>tcp 是面向连接的协议，它提供有序、可靠的数据传输，有确认应答、超时重传、流是控制和拥塞控制等机制。<br>udp 是无连接协议，它不保证数据的可靠性，仅传输数据，也不会等待对方的响应，没有顺序、流量和拥塞控制，也因此它的传输速度更快。<br>tcp主要用于可靠传输场景、例如文件传输、电商网站等。<br>udp主要用于游戏、直播等对数据可靠性要求不高的场景。</p><p><strong>为什么要 TCP，IP 层实现控制不行么?</strong></p><p>我们知道网络是分层实现的，网络协议的设计就是为了通信，从链路层到IP 层其实就已经可以完成通信了。<br>你看链路层不可或缺毕竟咱们电脑都是通过链路相互连接的，然后IP充当了地址的功能，所以通过IP 咱们找到了对方就可以进行通信了。<br>那加个 TCP 层干啥?IP 层实现控制不就完事了嘛?<br>之所以要提取出一个 TCP 层来实现控制是因为IP 层涉及到的设备更多一条数据在网络上传输需要经过很多设备，而设备之间需要靠 IP 来寻址。<br>假设IP 层实现了控制，那是不是涉及到的设备都需要关心很多事情?整体传输的效率是不是大打折扣了?</p><p>举个例子，假如 A要传输给F一个积木，但是无法直接传输到，需要经过 B、C、D、E这几个中转站之手。这里有两种情况:<br>假设 BCDE 都需要关心这个积木搭错了没，都拆开包裹仔细的看看，没问题了再装回去，最终到了F的手中。<br>假设 BCDE 都不关心积木的情况，来啥包裹只管转发就完事了，由最终的F自己来检查这个积木答错了没。<br>你觉得哪种效率高?明显是第二种，转发的设备不需要关心这些事，只管转发就完事!<br>所以把控制的逻辑独立出来成 TCP 层，让真正的接收端来处理，这样网络整体的传输效率就高了。</p><p><strong>TCP 的粘包和拆包能说说吗?</strong></p><p>粘包与半包只有在 TCP 传输的时候才会有，像 UDP 是不会有这种情况的，原因是因为 TCP 是面向流的，数据之间没有界限的，而 UDP 是有的界限的。<br>如果熟悉 TCP 和 UDP 报文格式的同学肯定知道，TCP 的包没有报文长度，而 UDP 的包有报文长度，这也说明了TCP 为什么是流式。<br>所以我为什么说上面的例子不太恰当，因为现实生活中快递的包裹之间其实是有界限的，TCP 则像流水，没有明确的界限。<br>然后 TCP 有发送缓冲区的概念，UDP 实际上是没这个概念。<br>假设 TCP 一次传输的数据大小超过发送缓冲区大小，那么一个完整的报文就需要被拆分成两个或更多的小报文这可能会产生半包的情况，当接收端收到不完整的数据，是无法解析成功的。<br>如果 TCP 一次传输的数据大小小于发送缓冲区，那么可能会跟别的报文合并起来一块发送，这就是粘包。</p><p><strong>说说 TCP 的三次握手?</strong></p><p><img src="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/image-20240807105337296.png" alt="image-20240807105337296"></p><p>客户端首先发送一个SYN(同步序列编号)消息给服务器，服务器收到后回复一个SYN-ACK(同步序列编号-确认)消息，最后客户端再发送一个ACK(确认)消息确认服务器已经收到SYN-ACK消息，从而完成三次握手，建立起-个可靠的TCP连接。</p><p><strong>初始序列号 ISN 怎么取值的?</strong></p><p>ISN：初始化序列号（initial sequence number），是在建立tcp三次握手的时候，存储在TCP头部的序列号位置中的数字的代称。也就是说，告诉对方我将要开始发送的初始化序列号是多少，两边都要发这个ISN，即tcp三次握手中第一次握手的SYN包和第二次握手的SYN+ACK包中都有这个数值。这个ISN的具体数值是不固定的。</p><p>如果写死一个值，比如0，那么假设已经建立好连接了，client 也发了很多包比如已经第 20 个包了然后网络断了之后 client 重新，端口号还是之前那个，然后序列号又从0开始，此时服务端返回第 20 个包的ack，客户端是不是傻了?<br>所以 RFC793 中认为 ISN 要和一个假的时钟绑定在一起<br>ISN 每四微秒加一，当超过 2的 32 次方之后又从0开始，要四个半小时左右发生ISN 回绕。<br>所以 ISN 变成一个递增值，真实的实现还需要加一些随机值在里面，防止被不法份子猜到 ISN。</p><p>初始序列号(ISN)的选取涉及多个考虑因素，包括连接唯一性、防止旧数据包干扰和增强安全性。现代系统通常采用时间戳法、随机化算法或两者结合的方法来生成ISN，以确保连接的可靠性和安全性。通过这些方法，ISN在保证唯一性和不可预测性方面发挥了重要作用，从而有效防止了TCP序列号预测攻击。</p><p><strong>SYN 超时了怎么处理?</strong></p><p> cient 发送 SYN 至 server 然后就挂了，此时 server 发送 SYN+ACK 就一直得不到回复。想到的就是重试，但是不能连续快速重试多次，假设 client 掉线了，你总得给它点时间恢复吧，所以呢需要慢慢重试，阶梯性重试。<br>在 Linux 中就是默认重试5次，并且就是阶梯性的重试，间隔就是1s、2s、4s、8s、16s，再第五次发出之后还得等 32s 才能知道这次重试的结果，所以说总共等63s 才能断开连接。</p><p><strong>SYN Flood 攻击有听过吗?</strong></p><p>SYN 超时需要耗费服务端 63s 的时间断开连接，也就说 63s 内服务端需要保持这个资源，所以不法分子就可以构造出大量的 client 向 server发 SYN 但就是不回 server。</p><p>使得 server 的 SYN 队列耗尽，无法处理正常的建连请求。<br>所以怎么办?<br>可以开启 tcp_syncookies，那就用不到 SYN 队列了。SYN 队列满了之后 TCP 根据自己的 ip、端口、然后对方的 ip、端口，对方 SYN 的序号，时间戳等一波操作生成个特殊的序号(即 cookie)发回去，如果对方是正常的 client 会把这个序号发回来，然后 server 根据这个序号建连。<br>或者调整 tcpsynackretries 减少重试的次数，设置 tcpmaxsyn_backlog 增加 SYN 队列数，设置tcp_abortonoverflow SYN 队列满了直接拒绝连接。</p><p><strong>说说 TCP 的四次挥手?</strong></p><p><img src="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/image-20240807111939389.png" alt="image-20240807111939389"></p><p>当一个方向另一个方向发送了最后一个数据包后，它会发送一个FIN(结束)消息，收到FIN消息的一方会发送个ACK(确认)消息确认收到FIN消息，然后等待对方的ACK消息。当双方都发送了FIN和ACK消息后，连接被关闭。</p><p><strong>为什么要四次挥手?</strong></p><p>因为 TCP 是全双工协议，也就是说双方都要关闭，每一方都向对方发送 FIN 和回应ACK。<br>就像我对你说我数据发完了，然后你回复好的你收到了。然后你对我说你数据发完了，然后我向你回复我收到<br>了。所以看起来就是四次。<br>从图中可以看到主动关闭方的状态是 FINWAIT1到 FINWAIT2 然后再到 TIMEWAIT，而被动关闭方是 CLOSEWAIT到 LAST ACK。</p><p><strong>挥手一定需要四次吗?</strong></p><p>假设 client 已经没有数据发送给 server 了，所以它发送 FIN 给 server 表明自己数据发完了，不再发了，如果这时候 server 还是有数据要发送给 client 那么它就是先回复 ack，然后继续发送数据。<br>等 server 数据发送完了之后再向 client 发送 FIN 表明它也发完了，然后等 client 的 ACK 这种情况下就会有四次挥手。<br>那么假设 client 发送 FIN 给 server 的时候 server 也没数据给 cient，那么 server 就可以将 ACK 和它的 FIN 一起发给client ，然后等待 client的 ACK，这样不就三次挥手了?</p><p><strong>为什么要有 TIME_WAIT?</strong></p><p>断开连接发起方在接受到接受方的 FIN 并回复 ACK之后并没有直接进入 CLOSED 状态，而是进行了一波等待等待时间为 2MSL。<br>MSL是 Maximum Segment Lifetime，即报文最长生存时间，RFC 793 定义的 MSL 时间是2分钟，Linux 实际实现是 30s，那么 2MSL是一分钟。<br>那么为什么要等 2MSL呢?<br>就是怕被动关闭方没有收到最后的 ACK，如果被动方由于网络原因没有到，那么它会再次发送 FIN， 此时如果主动关闭方已经 CLOSED 那就傻了，因此等一会儿。<br>假设立马断开连接，但是又重用了这个连接，就是五元组完全一致，并且序号还在合适的范围内，虽然概率很低但理论上也有可能，那么新的连接会被已关闭连接链路上的一些残留数据干扰，因此给予一定的时间来处理一些残留数据。</p><p><strong>超时重传机制是为了解决什么问题?</strong></p><p>提到 TCP 要提供可靠的传输，那么网络又是不稳定的如果传输的包对方没收到却又得保证可靠那么就必须重传。<br>TCP 的可靠性是靠确认号的，比如我发给你1、2、3、4这4个包，你告诉我你现在要5那说明前面四个包你都收到了，就是这么回事儿。<br>不过这里要注意，SeqNum 和 ACK 都是以字节数为单位的，也就是说假设你收到了1、2、4 但是3没有收到你不能 ACK 5，如果你回了5 那么发送方就以为你5之前的都收到了。<br>所以只能回复确认最大连续收到包，也就是 3。<br>而发送方不清楚 3、4 这两个包到底是还没到呢还是已经丢了，于是发送方需要等待，这等待的时间就比较讲究了。<br>如果太心急可能 ACK已经在路上了，你这重传就是浪费资源了，如果太散漫，那么接收方急死了，这死鬼怎么还不发包来，我等的花儿都谢了。<br>所以这个等待超时重传的时间很关键，怎么搞?聪明的小伙伴可能一下就想到了，你估摸着正常来回一趟时间是多少不就好了，我就等这么长。<br>这就来回一趟的时间就叫 RTT，即 Round Trip Time，然后根据这个时间制定超时重传的时间 RTO，即Retransmission Timeout.</p><p><strong>为什么还需要快速重传机制?</strong></p><p>超时重传是按时间来驱动的，如果是网络状况真的不好的情况，超时重传没问题，但是如果网络状况好的时候只是恰巧丢包了，那等这么长时间就没必要。<br>于是又引入了数据驱动的重传叫快速重传，什么意思呢?就是发送方如果连续三次收到对方相同的确认号，那么马上重传数据。<br>因为连续收到三次相同 ACK 证明当前网络状况是 ok的，那么确认是丢包了，于是立马重发，没必要等这么久。</p><p><strong>SACK 的引入是为了解决什么问题?</strong></p><p>SACK 即 Selective Acknowledgment，它的引入就是为了解决发送方不知道该重传哪些数据的问题我们来看下面的图就知道了。</p><p><img src="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/image-20240807150112699.png" alt="image-20240807150112699"></p><p>SACK 就是接收方会回传它已经接受到的数据，这样发送方就知道哪一些数据对方已经收到了，所以就可以选择性的发送丢失的数据。<br>如图，通过 ACK 告知我接下来要 5500 开始的数据，并一直更新 SACK，6000-6500 我收到了，6000-7000的数据我收到了，6000-7500的数据我收到了，发送方很明确的知道，5500-5999的那一波数据应该是丢了，于是重传。<br>而且如果数据是多段不连续的，SACK 也可以发送，比如 SACK0-500,1000-1500，2000-2500。就表明这几段已经收到了。</p><p>D-SACK 其实是 SACK 的扩展，它利用 SACK 的第一段来描述重复接受的不连续的数据序号,如果第一段描述的范围被 ACK 覆盖，说明重复了，比如我都 ACK 到6000了你还给我回 SACK 5000-5500 呢?<br>说白了就是从第一段的反馈来和已经接受到的 ACK比一比，参数是 tcp_dsack，Linux 2.4之后默认开启。<br>那知道重复了有什么用呢?<br>1)知道重复了说明对方收到刚才那个包了，所以是回来的 ACK 包丢了。<br>2)是不是包乱序的，先发的包后到?<br>3)是不是自己太着急了，RTO 太小了?<br>4)是不是被数据复制了，抢先一步呢?</p><p><strong>滑动窗口的作用是什么?</strong></p><p> TCP 有序号，并且还有重传，但是这还不够，还需要根据情况来控制一下发送速率，因为网络是复杂多变的，有时候就会阻塞住，而有时候又很通畅。<br>所以发送方需要知道接收方的情况，好控制一下发送的速率，不至于蒙着头一个劲儿的发然后接受方都接受不过来。<br>因此 TCP 就有个叫滑动窗口的东西来做流量控制，也就是接收方告诉发送方我还能接受多少数据，然后发送方就可以根据这个信息来进行数据的发送,<br>以下是发送方维护的窗口，就是黑色圈起来的。<img src="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/image-20240807151407392.png" alt="image-20240807151407392"></p><p><img src="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/image-20240807151327175.png" alt="image-20240807151327175"></p><p><strong>已经有滑动窗口了为什么还要拥塞控制?</strong></p><p>加了拥塞控制是因为 TCP 不仅仅就管两端之间的情况，还需要知晓一下整体的网络情形，毕竟只有大家都守规矩了道路才会通畅。<br>前面我们提到了重传，如果不管网络整体的情况，肯定就是对方没给 ACK，那我就无脑重传。如果此时网络状况很差，所有的连接都这样无脑重传，是不是网络情况就更差了，更加拥堵了，所以需要个拥塞控制，来避免这种情况的发送。</p><p><strong>说说拥塞控制的步骤?</strong></p><p>主要有以下几个步骤来搞:<br>1)慢启动，探探路。<br>2)拥塞避免，感觉差不多了减速看看<br>3)拥塞发生快速重传&#x2F;恢复</p><p><img src="/2024/08/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/image-20240807152255383.png" alt="image-20240807152255383"></p><p>慢启动，就是新司机上路慢慢来，初始化cwnd(Congestion Window)为1，然后每收到一个 ACK 就 cwnd++并且每过一个RTT，cwnd&#x3D;2*cwnd。<br>线性中带着指数，指数中又夹杂着线性增。<br>然后到了一个阈值，也就是 ssthresh(slow start threshold)的时候就进入了拥塞避免阶段。<br>这个阶段是每收到一个 ACK 就 cwnd&#x3D; cwnd + 1&#x2F;cwnd并且每-个 RTT 就 cwnd++。<br>可以看到都是线性增。<br>然后就是一直增，直到开始丢包的情况发生，前面已经分析到重传有两种，!，一种是超时重传，一种是快速重传。<br>如果发生超时重传的时候，那说明情况有点糟糕，于是直接把 ssthresh 置为当前 cwnd 的一半，然后 cwnd 直接变为 1，进入慢启动阶段。<br>如果是快速重传，那么这里有两种实现，一种是 TCP Tahoe ，和超时重传一样的处理。<br>一种是 TCP Reno，这个实现是把 cwnd&#x3D;cwnd&#x2F;2 ，然后把 ssthresh 设置为当前的 cwnd<br>然后进入快速恢复阶段，将cwnd&#x3D; cwnd+3(因为快速重传有三次)，重传 DACK指定的包，如果再收到一个DACK则 cwnd++，如果收到是正常的 ACK 那么就将 cwnd 设为 ssthresh 大小，进入拥塞避免阶段。<br>可以看到快速恢复就重传了指定的一个包，那有可能是很多包都丢了，然后其他的包只能等待超时重传，超时重传就会导致 cwnd 减半，多次触发就指数级下降。<br>所以又搞了个 New Reno，多加了个New，它是在没有SACK的情况下改进快速恢复，它会观察重传 DACK 指定的包的响应 ACK 是否是已,经发送的最大 ACK，比如你发了1、2、3、4，对方没收到 2，但是 3、4都收到了，于是你重传 2 之后 ACK 肯定是 5，说明就丢了这一个包。<br>不然就是还有其他包丢了，如果就丢了一个包就是之前的过程一样，如果还有其他包丢了就继续重传，直到 ACK是全部的之后再退出快速恢复阶段。<br>简单的说就是一直探测到全部包都收到了再结束这个环节。<br>还有个 FACK，它是基于 SACK 用来作为重传过程中的拥赛控制，相对于上面的 New Reno 我们就知道它有 SACK所以不需要一个一个试过去。</p><p><strong>ARP 和 RARP 分别是什么?有什么区别?</strong></p><p>ARP(Address Resolution Protocol)将IP 地址转换为 MAC 地址，因为最终需要找到 MAC 地址才能跟具体的设<br>备通信。而 RARP(Reverse Address Resolution Protocol)用于将 MAC 地址转换为IP 地址，比如一些设备启动的时候,需要根据 RARP 来得知分配给它的ip 是什么。</p><p>ARP协议的工作原理<br>1.获取目标设备的IP地址,<br>2.检查自己的ARP缓存表，如果查到了对应的MAC地址，则直接发送数据包.<br>3.发送ARP请求，包含自己的IP地址，MAC地址，以及需要解析的IP地址，广播到局域网中所有设备。<br>4.目标收到ARP请求后，首先会检查请求的IP地址是否与自己的IP地址匹配，如匹配，则创建ARP响应消息，将自己的IP地址及对应的MAC地址返回给请求方。<br>5.当ARP请求方收到了ARP响应，会更新自己的ARP缓存，将目标IP及对应的MAC写入ARP缓存表:</p><p><strong>TCP&#x2F;IP 四层模型是什么?</strong></p><p>四层主要指的是:网络接口层、互联网层、传输层和应用层。<br>网络接口层负责在计算机和网络硬件之间传输数据<br>互联网层(网络层)通过IP 协议提供数据包的路由和转发<br>传输层通过 TCP 和 UDP 协议提供端到端的通信服务<br>应用层通过各种协议提供网络应用程序的功能，如 HTTP等</p><p><strong>七层模型是什么?</strong></p><p>OSI七层模型是计算机网络通信的标准模型，从底层到顶层依次为:物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。<br>1)物理层，主要描述物理层面的传输，比如光纤、电缆<br>2)数据链路层，可以认为是 MAC 层面相邻节点的传输。<br>3)网络层，IP 层面的寻址、路由。<br>4)传输层，TCP 和 UDP 层的传输<br>5)会话层，负责会话状态的保持、管理与同步，<br>6)表示层，些数据的转化，压缩和编码，<br>7)应用层，http 之类的协议的交互转化:</p><p><strong>Cookie、Session、Token 之间有什么区别?</strong></p><p>Cookie 存储在浏览器，生命周期可以由服务器端设置。<br>Session 存储在服务器，生命周期由服务器端控制。<br>Token(如JWT)存储在客户端，是一个加密的令牌，可以跨多个会话使用。<br>简单来说，Cookie 和Session 更适合用于单次会话的认证和状态管理，而 Token 更适合用于跨会话的认证和状态管理。</p><p><strong>JWT Token 听过吗?</strong></p><p>Token(如JWT)其实就是一个加密的令牌，服务端通过一定的方式将用户的信息加密生成一个JT Token，后续客户端带着这个 token 来访问服务端时，服务端可以解密得到对应的用户信息，这样就能进行身份和权限的验证了。</p><p><strong>当你在浏览器输入一个域名回车后，会发生什么?</strong></p><p>请求将域名解析为对应的IP 地址。DNS 服务器返回简单流程如下:浏览器会向DNS服务器发送一个查询请求，IP 地址后，浏览器使用该IP 地址向服务器发起 HTTP 请求。<br>服务器收到请求后，做对应的处理，且返回相应的网页内容。浏览器接收到网页内容后，解析 HTML、CSSJavaScript 等文件，最终显示网页<br>整个过程涉及到 DNS 解析、HTTP 请求、服务器响应和浏览器解析等步骤。</p><p><strong>简单谈谈你对 CDN 的理解?</strong></p><p>CDN(Content Delivery Network)是一种分布式网络架构，用于加速互联网内容的分发<br>因为网络传输有距离限制，部署杭州的服务器，不同地区的用户访问得到响应的时长是不一样的，杭州的用户来访问肯定比美国的用户来访问快多了。<br>所以就弄了个 CDN 来加快内容的分发:<br>它通过在全球多个地理位置部署服务器，当用户请求内容时，CDN 会根据用户的地理位置，将请求转发到最近的缓存服务器上。这样可以减少数据传输的延迟，提高用户访问速度，同时减轻源服务器的负载。<br>CDN 通常用于加速静态内容(如图片、视频、静态页面等)的访问，提高网站的性能和用户体验。</p><p><strong>简单谈谈你对 DNS 的理解?</strong></p><p>DNS(Domain Name System)是一个用于将域名转换为IP 地址的分布式数据库系统<br>它的工作原理是，当用户输入一个域名时，DNS 服务器会查询该域名对应的IP 地址，并将结果返回给用户。这样，用户就可以通过域名访问网站，而不需要记住复杂的IP地址。DNS 的使用简化了网络访问过程，提高了网络通信的效率。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>笔试练习记录(一)</title>
    <link href="/2024/07/19/%E7%AC%94%E8%AF%95%E7%BB%83%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)/"/>
    <url>/2024/07/19/%E7%AC%94%E8%AF%95%E7%BB%83%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)/</url>
    
    <content type="html"><![CDATA[<h1 id="需求：输入一行字符串，按空格进行分割，取子串存入。"><a href="#需求：输入一行字符串，按空格进行分割，取子串存入。" class="headerlink" title="需求：输入一行字符串，按空格进行分割，取子串存入。"></a>需求：输入一行字符串，按空格进行分割，取子串存入。</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sstream&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    string str_line;<br>    <span class="hljs-built_in">getline</span>(cin,str_line);<br><span class="hljs-function">stringstream <span class="hljs-title">ss</span><span class="hljs-params">(str_line)</span></span>;<br>string str_tmp;<br><span class="hljs-keyword">while</span>(ss &gt;&gt; str_tmp)<br>    cout &lt;&lt; str_tmp&lt;&lt;endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="练习题目"><a href="#练习题目" class="headerlink" title="练习题目"></a>练习题目</h4><p>对于一个文件系统，第一行输入所有的父目录名称，第二行输入所有的子目录&#x2F;文件名称，第三行输入待查询的文件或目录名称。对于查询的目录或文件名，如果存在子目录或文件，需要按输入的顺序，按层级输出所有的子目录和文件。“&#x2F;”表示根目录，没有父目录。</p><h4 id="输入描述"><a href="#输入描述" class="headerlink" title="输入描述"></a>输入描述</h4><p>第一行是一个由所有的父目录名称组成的字符串，按空格分开。第二行是对应父目录的所有子目录或文件名组成的字符串，按空格分开。第三行是查询的文件名或目录名。</p><h4 id="输出描述"><a href="#输出描述" class="headerlink" title="输出描述"></a>输出描述</h4><p>按输入的顺序逐层输出所有的子目录和文件，包括查询的目录&#x2F;文件本身</p><h4 id="示例1："><a href="#示例1：" class="headerlink" title="示例1："></a>示例1：</h4><p>输入：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">/ / / home usr <br>home opt env usr <span class="hljs-number">1.l</span>og<br>home<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">home usr <span class="hljs-number">1.l</span>og<br></code></pre></td></tr></table></figure><h4 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstring&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sstream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;queue&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;string&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    vector&lt;string&gt; parent_dir;<br>    vector&lt;string&gt; children_dir;<br>    string parent_line;<br>    string children_line;<br>    string goal;<br>    <span class="hljs-built_in">getline</span>(cin,parent_line);<br>    <span class="hljs-built_in">getline</span>(cin,children_line);<br>    <span class="hljs-built_in">getline</span>(cin,goal);<br>    <span class="hljs-function">stringstream <span class="hljs-title">ss1</span><span class="hljs-params">(parent_line)</span></span>;<br>    <span class="hljs-function">stringstream <span class="hljs-title">ss2</span><span class="hljs-params">(children_line)</span></span>;<br>    string str_tmp;<br>    <span class="hljs-keyword">while</span>(ss1 &gt;&gt; str_tmp)<br>        parent_dir.<span class="hljs-built_in">push_back</span>(str_tmp);<br>    <span class="hljs-keyword">while</span>(ss2 &gt;&gt; str_tmp)<br>        children_dir.<span class="hljs-built_in">push_back</span>(str_tmp);<br>    <span class="hljs-comment">//输入完成</span><br>    <span class="hljs-type">int</span> n = parent_dir.<span class="hljs-built_in">size</span>();<br>    vector&lt;string&gt; ans;<br>    ans.<span class="hljs-built_in">push_back</span>(goal);<br>    queue&lt;string&gt; q;<br>    q.<span class="hljs-built_in">push</span>(goal);<br>    <span class="hljs-keyword">while</span>(!q.<span class="hljs-built_in">empty</span>())&#123;<br>        str_tmp = q.<span class="hljs-built_in">front</span>();q.<span class="hljs-built_in">pop</span>();<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">if</span>(str_tmp.<span class="hljs-built_in">compare</span>(parent_dir[i]) == <span class="hljs-number">0</span>)&#123;<br>                ans.<span class="hljs-built_in">push_back</span>(children_dir[i]);<br>                q.<span class="hljs-built_in">push</span>(children_dir[i]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> str: ans)&#123;<br>        cout&lt;&lt;str&lt;&lt;<span class="hljs-string">&#x27; &#x27;</span>;<br>    &#125;<br>    cout&lt;&lt;endl;<br>        <span class="hljs-comment">//cout &lt;&lt; str_tmp&lt;&lt;endl;</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="需求：拓扑排序，按顺序完成事件。"><a href="#需求：拓扑排序，按顺序完成事件。" class="headerlink" title="需求：拓扑排序，按顺序完成事件。"></a>需求：拓扑排序，按顺序完成事件。</h1><h4 id="练习题目-1"><a href="#练习题目-1" class="headerlink" title="练习题目"></a>练习题目</h4><p>一组n个软件和k（k &lt; (n*(n - 1)&#x2F;2)）个依赖关系,若干组查询，查询两个软件的前者是否是后者的直接依赖或间接依赖。（对于[a,b]判断a是否是b的前驱节点）</p><h4 id="输入描述-1"><a href="#输入描述-1" class="headerlink" title="输入描述"></a>输入描述</h4><p>第一行输入两个正整数<code>n</code>和<code>d</code> ，代表软件的个数和依赖关系。后面<code>d</code>行输入相应的依赖关系。下一行输入一个正整数<code>q</code>，代表查询的组数。之后<code>q</code>行输入相应的查询。</p><h4 id="输出描述-1"><a href="#输出描述-1" class="headerlink" title="输出描述"></a>输出描述</h4><p>第一行输出<code>q</code>。之后q行每行输出一个正整数，如果是依赖关系，输出1，否则输出0。</p><h4 id="示例1：-1"><a href="#示例1：-1" class="headerlink" title="示例1："></a>示例1：</h4><p>输入：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-number">3</span> <span class="hljs-number">3</span><br><span class="hljs-number">0</span> <span class="hljs-number">1</span><br><span class="hljs-number">1</span> <span class="hljs-number">2</span><br><span class="hljs-number">0</span> <span class="hljs-number">2</span><br><span class="hljs-number">2</span><br><span class="hljs-number">1</span> <span class="hljs-number">0</span><br><span class="hljs-number">0</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-number">2</span><br><span class="hljs-number">0</span><br><span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h4 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a>完整代码</h4><p>BFS方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unordered_map&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;queue&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">has_dependency</span><span class="hljs-params">(unordered_map&lt;<span class="hljs-type">int</span>, vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; graph, <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (start == end) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>unordered_map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">bool</span>&gt; visited;<br>queue&lt;<span class="hljs-type">int</span>&gt; q;<br>q.<span class="hljs-built_in">push</span>(start);<br>visited[start] = <span class="hljs-literal">true</span>;<br><br><span class="hljs-keyword">while</span> (!q.<span class="hljs-built_in">empty</span>()) &#123;<br>    <span class="hljs-type">int</span> node = q.<span class="hljs-built_in">front</span>();<br>    q.<span class="hljs-built_in">pop</span>();<br>    <br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> neighbor : graph[node]) &#123;<br>        <span class="hljs-keyword">if</span> (neighbor == end) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (!visited[neighbor]) &#123;<br>            q.<span class="hljs-built_in">push</span>(neighbor);<br>            visited[neighbor] = <span class="hljs-literal">true</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> n, d;<br>    cin &gt;&gt; n &gt;&gt; d;<br>    unordered_map&lt;<span class="hljs-type">int</span>, vector&lt;<span class="hljs-type">int</span>&gt;&gt; graph;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; d; ++i) &#123;<br>        <span class="hljs-type">int</span> u, v;<br>        cin &gt;&gt; u &gt;&gt; v;<br>        graph[u].<span class="hljs-built_in">push_back</span>(v);<br>    &#125;<br><br>    <span class="hljs-type">int</span> q;<br>    cin &gt;&gt; q;<br>    vector&lt;pair&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">queries</span>(q);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; q; ++i) &#123;<br>        cin &gt;&gt; queries[i].first &gt;&gt; queries[i].second;<br>    &#125;<br><br>    cout &lt;&lt; q &lt;&lt; endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; query : queries) &#123;<br>        <span class="hljs-type">int</span> u = query.first, v = query.second;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">has_dependency</span>(graph, u, v)) &#123;<br>            cout &lt;&lt; <span class="hljs-number">1</span> &lt;&lt; endl;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            cout &lt;&lt; <span class="hljs-number">0</span> &lt;&lt; endl;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>DFS方法:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unordered_map&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unordered_set&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-comment">// 判断从 start 到 end 是否有路径</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">has_dependency</span><span class="hljs-params">(unordered_map&lt;<span class="hljs-type">int</span>, vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; graph, <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end, unordered_set&lt;<span class="hljs-type">int</span>&gt;&amp; visited)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (start == end) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    visited.<span class="hljs-built_in">insert</span>(start);<br>    <br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> neighbor : graph[start]) &#123;<br>        <span class="hljs-keyword">if</span> (visited.<span class="hljs-built_in">find</span>(neighbor) == visited.<span class="hljs-built_in">end</span>()) &#123;<br>            <span class="hljs-keyword">if</span> (<span class="hljs-built_in">has_dependency</span>(graph, neighbor, end, visited)) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> n, d;<br>    cin &gt;&gt; n &gt;&gt; d;<br>    <br>    unordered_map&lt;<span class="hljs-type">int</span>, vector&lt;<span class="hljs-type">int</span>&gt;&gt; graph;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; d; ++i) &#123;<br>        <span class="hljs-type">int</span> u, v;<br>        cin &gt;&gt; u &gt;&gt; v;<br>        graph[u].<span class="hljs-built_in">push_back</span>(v);<br>    &#125;<br>    <br>    <span class="hljs-type">int</span> q;<br>    cin &gt;&gt; q;<br>    vector&lt;pair&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">queries</span>(q);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; q; ++i) &#123;<br>        cin &gt;&gt; queries[i].first &gt;&gt; queries[i].second;<br>    &#125;<br>    <br>    cout &lt;&lt; q &lt;&lt; endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; query : queries) &#123;<br>        <span class="hljs-type">int</span> u = query.first, v = query.second;<br>        unordered_set&lt;<span class="hljs-type">int</span>&gt; visited;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">has_dependency</span>(graph, u, v, visited)) &#123;<br>            cout &lt;&lt; <span class="hljs-number">1</span> &lt;&lt; endl;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            cout &lt;&lt; <span class="hljs-number">0</span> &lt;&lt; endl;<br>        &#125;<br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MapReduce框架原理</title>
    <link href="/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/"/>
    <url>/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="MapReduce框架原理"><a href="#MapReduce框架原理" class="headerlink" title="MapReduce框架原理"></a>MapReduce框架原理</h2><img src="/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/框架.png" alt="框架" style="zoom:80%;"><h3 id="切片与MapTask并行度决定机制"><a href="#切片与MapTask并行度决定机制" class="headerlink" title="切片与MapTask并行度决定机制"></a>切片与MapTask并行度决定机制</h3><p><strong>数据块：</strong>Block是HDFS物理上把数据分成一块一块。数据块是HDFS存储数据单位。</p><p><strong>数据切片：</strong>数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask。</p><p>1）一个Job的Map阶段并行度由客户端在提交Job时的切片数决定</p><p>2）每一个Split切片分配一个MapTask并行实例处理</p><p>3）默认情况下，切片大小&#x3D;BlockSize</p><p>4)切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p><h3 id="Job提交流程源码解析"><a href="#Job提交流程源码解析" class="headerlink" title="Job提交流程源码解析"></a>Job提交流程源码解析</h3><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs stata">waitForCompletion()<br><br>submit();<br><br><span class="hljs-comment">// 1建立连接</span><br>connect();<br><span class="hljs-comment">// 1）创建提交Job的代理</span><br>new <span class="hljs-keyword">Cluster</span>(getConfiguration());<br><span class="hljs-comment">// （1）判断是本地运行环境还是yarn集群运行环境</span><br>initialize(jobTrackAddr, <span class="hljs-keyword">conf</span>); <br><br><span class="hljs-comment">// 2 提交job</span><br>submitter.submitJobInternal(Job.this, <span class="hljs-keyword">cluster</span>)<br><br><span class="hljs-comment">// 1）创建给集群提交数据的Stag路径</span><br>Path jobStagingArea = JobSubmissionFiles.getStagingDir(<span class="hljs-keyword">cluster</span>, <span class="hljs-keyword">conf</span>);<br><br><span class="hljs-comment">// 2）获取jobid ，并创建Job路径</span><br>JobID jobId = submitClient.getNewJobID();<br><br><span class="hljs-comment">// 3）拷贝jar包到集群</span><br>copyAndConfigureFiles(job, submitJobDir);<br>rUploader.uploadFiles(job, jobSubmitDir);<br><br><span class="hljs-comment">// 4）计算切片，生成切片规划文件</span><br>writeSplits(job, submitJobDir);<br>maps = writeNewSplits(job, jobSubmitDir);<br><span class="hljs-keyword">input</span>.getSplits(job);<br><br><span class="hljs-comment">// 5）向Stag路径写XML配置文件</span><br>writeConf(<span class="hljs-keyword">conf</span>, submitJobFile);<br><span class="hljs-keyword">conf</span>.writeXml(<span class="hljs-keyword">out</span>);<br><br><span class="hljs-comment">// 6）提交Job,返回提交状态</span><br>status = submitClient.submitJob(jobId, submitJobDir.<span class="hljs-keyword">toString</span>(), job.getCredentials());<br><br></code></pre></td></tr></table></figure><p><img src="/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B.png" alt="Job提交流程"></p><p>在运行MapReduce程序时，输入的文件格式包括：基于行的日志文件、二进制格式文件、数据库表等。那么，针对不同的数据类型FileInputFormat常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat和自定义InputFormat等。</p><p>TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量， LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符），Text类型。</p><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。</p><p>CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p><p>生成切片过程包括：虚拟存储过程和切片过程两部分。</p><p>（1）虚拟存储过程：</p><p>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</p><p>（2）切片过程：</p><p>（a）判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。</p><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p><p>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：</p><p>1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）</p><p>最终会形成3个切片，大小分别为：（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop的计算执行模块MapReduce</title>
    <link href="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/"/>
    <url>/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/</url>
    
    <content type="html"><![CDATA[<h2 id="MapReduce定义"><a href="#MapReduce定义" class="headerlink" title="MapReduce定义"></a>MapReduce定义</h2><p>MapReduce是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。</p><p>MapReduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个Hadoop集群上。</p><p><strong>优点：</strong></p><p>1.MapReduce易于编程</p><p>2.良好的扩展性</p><p>3.高容错性</p><p>4.适合PB级以上海量数据的离线处理</p><p><strong>缺点：</strong></p><p>1.不擅长实时计算</p><p>2.不擅长流式计算<del>（Sparkstreaming、Flink）</del></p><p>3.不擅长DAG（有向无环图）计算<del>（Spark）</del></p><h2 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h2><p><img src="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/MR%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3.png" alt="MR核心思想"></p><p><img src="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/mapper%E9%98%B6%E6%AE%B5.png" alt="mapper阶段"></p><p><img src="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/reduce%E9%98%B6%E6%AE%B5.png" alt="reduce阶段"></p><p>一个完整的MapReduce程序在分布式运行时有三类实例进程：</p><p>（1）<strong>MrAppMaster</strong>：负责整个程序的过程调度及状态协调。</p><p>（2）<strong>MapTask</strong>：负责Map阶段的整个数据处理流程。</p><p>（3）<strong>ReduceTask</strong>：负责Reduce阶段的整个数据处理流程。</p><h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>1）<strong>什么是序列化</strong></p><p><strong>序列化</strong>就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。 </p><p><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。</p><p>2）<strong>为什么要序列化</strong></p><p>一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</p><p>3）为什么不用Java的序列化</p><p>Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop自己开发了一套序列化机制（Writable）。</p><p>4）Hadoop序列化特点：</p><p>（1）<strong>紧凑</strong> <strong>：</strong>高效使用存储空间。</p><p>（2）<strong>快速：</strong>读写数据的额外开销小。</p><p>（3）<strong>互操作：</strong>支持多语言的交互.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop之HDFS</title>
    <link href="/2024/05/16/Hadoop%E4%B9%8BHDFS/"/>
    <url>/2024/05/16/Hadoop%E4%B9%8BHDFS/</url>
    
    <content type="html"><![CDATA[<h1 id="Hadoop三大件之Hive"><a href="#Hadoop三大件之Hive" class="headerlink" title="Hadoop三大件之Hive"></a>Hadoop三大件之Hive</h1><h2 id="HDFS的背景和意义"><a href="#HDFS的背景和意义" class="headerlink" title="HDFS的背景和意义"></a>HDFS的背景和意义</h2><p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。<strong>HDFS（Hadoop Distributed File System）只是分布式文件管理系统中的一种。</strong>其他还有诸如 <strong>Amazon S3 (Simple Storage Service)<strong>、</strong>Google Cloud Storage</strong>、<strong>Microsoft Azure Blob Storage</strong>等。</p><p>HDFS（Hadoop Distributed File System），用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p><p>HDFS的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭之后就不需要改变。</p><h2 id="HDFS的优缺点"><a href="#HDFS的优缺点" class="headerlink" title="HDFS的优缺点"></a>HDFS的优缺点</h2><p>优点：</p><p>1.高容错性：数据自动保存多个副本</p><p>2.大数据处理：数据规模大，能达到TB甚至PB级别的数据；文件规模大，能达到百万文件数量。</p><p>3.可靠性和经济性：可构建在普通计算机上，通过多副本机制提高可靠性。</p><p>缺点：</p><p>1.无法做到低延时数据访问。</p><p>2.无法高效对大量小文件存储。</p><p>3.不支持并发写入、文件随机修改。（仅支持数据append）</p><h2 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h2><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405201620844.png" alt="hdfs组成架构"></p><p><strong>NameNode（NN）：</strong></p><p>（1）管理HDFS的名称空间；</p><p>（2）配置副本策略；</p><p>（3）管理数据块（Block）映射信息；</p><p>（4）处理客户端读写请求。</p><p><strong>DataNode：</strong></p><p>（1）存储实际的数据块；</p><p>（2）执行数据块的读写操作。</p><p><strong>Client：</strong></p><p>（1）文件切分，文件上传后被切分为Block，然后进行上传。</p><p>（2）与NameNode交互，获取文件的位置信息。</p><p>（3）与DataNode交互，读取或写入数据。</p><p>（4）提供一些命令来管理HDFS，比如NN的格式化和访问HDFS。</p><p><strong>Secondary NameNode：</strong></p><p>（1）辅助NameNode，分担其工作量。（比如定期合并Fsimage和Edits,并推给NN）</p><p>（2）紧急情况下，可辅助恢复NameNode。</p><p>文件块（Block）：HDFS中的文件在物理上是分块存储，大小一般为128或256M。与磁盘传输速率相关。</p><h2 id="HDFS的Shell命令"><a href="#HDFS的Shell命令" class="headerlink" title="HDFS的Shell命令"></a>HDFS的Shell命令</h2><p><strong>上传命令：</strong></p><p>-moveFromLocal：从本地剪切粘贴到HDFS</p><p>-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><p>-put：等同于copyFromLocal，生产环境更习惯用put</p><p>-appendToFile：追加一个文件到已经存在的文件末尾</p><p><strong>下载命令：</strong></p><p>-copyToLocal：从HDFS拷贝到本地</p><p>-get：等同于copyToLocal，生产环境更习惯用get</p><h2 id="HDFS的写数据流程"><a href="#HDFS的写数据流程" class="headerlink" title="HDFS的写数据流程"></a>HDFS的写数据流程</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png" alt="写数据流程"></p><p>（1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p><p>（2）NameNode返回是否可以上传。</p><p>（3）客户端请求第一个 Block上传到哪几个DataNode服务器上。</p><p>（4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。</p><p>（5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p><p>（6）dn1、dn2、dn3逐级应答客户端。</p><p>（7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</p><p>（8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p><p><strong>副本节点选择</strong></p><p>第一个副本在Client所处的节点上。如果客户端在集群外，随机选一个。</p><p>第二个副本在另一个机架的随机一个节点。</p><p>第三个副本在第二个副本所在机架的随机节点。</p><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9.png" alt="副本存储节点选择"></p><h2 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png" alt="读数据流程"></p><p>（1）客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p><p>（2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</p><p>（3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</p><p>（4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</p><h2 id="NameNode工作机制"><a href="#NameNode工作机制" class="headerlink" title="NameNode工作机制"></a>NameNode工作机制</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/nn%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png" alt="nn工作机制"></p><p>1）第一阶段：NameNode启动</p><p>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p><p>（2）客户端对元数据进行增删改的请求。</p><p>（3）NameNode记录操作日志，更新滚动日志。</p><p>（4）NameNode在内存中对元数据进行增删改。</p><p>2）第二阶段：Secondary NameNode工作</p><p>（1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</p><p>（2）Secondary NameNode请求执行CheckPoint。</p><p>（3）NameNode滚动正在写的Edits日志。</p><p>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</p><p>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p><p>（6）生成新的镜像文件fsimage.chkpoint。</p><p>（7）拷贝fsimage.chkpoint到NameNode。</p><p>（8）NameNode将fsimage.chkpoint重新命名成fsimage。</p><h2 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/DN%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="DN工作流程"></p><p>（1）一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</p><p>（2）DataNode启动后向NameNode注册，通过后，周期性（6小时）的向NameNode上报所有的块信息。</p><p>DN向NN汇报当前解读信息的时间间隔，默认6小时。</p><p>（3）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</p><p>（4）集群运行中可以安全加入和退出一些机器。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>针对HDFS的学习集中在各个组成部分的工作机制，而对里面的细节没有深入，比如Fsimage和Edits的解析。后续在生产环境再深入学习吧。HDFS组成部分间的成员角色和工作流程诠释了分布式文件系统分块存储的特点，同时兼顾传输效率和可靠性！</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop搭建完全分布式运行模式</title>
    <link href="/2024/05/11/Hadoop%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    <url>/2024/05/11/Hadoop%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="Hadoop搭建之完全分布式运行模式"><a href="#Hadoop搭建之完全分布式运行模式" class="headerlink" title="Hadoop搭建之完全分布式运行模式"></a>Hadoop搭建之完全分布式运行模式</h1><h2 id="起因："><a href="#起因：" class="headerlink" title="起因："></a>起因：</h2><p>课题组的服务器的大数据集群是好几年前的师兄们安装配置，并由星环公司提供技术服务，因此对基本的大数据环境搭建并不熟悉。这篇文章就是记录从头开始搭建Hadoop的生产环境，并记录遇到的问题和解决过程。</p><h2 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a>准备工作：</h2><p>1.四台虚拟机zzyhadoop01\02\03\04，系统CentOS7，配置好IP</p><p>2.JDK和Hadoop的软件包</p><p>3.Linux远程连接工具Xshell和文件传输工具Xftp</p><h2 id="配置开始："><a href="#配置开始：" class="headerlink" title="配置开始："></a>配置开始：</h2><p>02号机已经安装好JDK和Hadoop，使用scp（secure copy，安全拷贝）将JDK和Hadoop复制到03、04号机上。</p><figure class="highlight plaintext"><figcaption><span>命令</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Linux">[root@zzyhadoop02 ~]# scp -r /opt/module/jdk1.8.0_212 root@zzyhadoop03:/opt/module<br>[root@zzyhadoop03 ~]# scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/<br>[root@zzyhadoop03 ~]# scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module<br>##上述所在主机不同，要分清从哪里拿文件，送到哪里去<br>## scp    -r        $pdir/$fname             $user@$host:$pdir/$fname<br>## 命令   递归     要拷贝的文件路径/名称   目的地用户@主机:目的地路径/名称<br><br></code></pre></td></tr></table></figure><p><strong>rsync远程同步工具</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">rsync</span>   -av    <span class="hljs-variable">$pdir</span>/<span class="hljs-variable">$fname</span>       <span class="hljs-variable">$user</span>@<span class="hljs-variable">$host</span>:<span class="hljs-variable">$pdir</span>/<span class="hljs-variable">$fname</span><br><span class="hljs-comment">## -a 归档拷贝 -v 显示复制过程</span><br><span class="hljs-comment">##命令  选项参数  要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称</span><br></code></pre></td></tr></table></figure><p>同步环境变量到03、04</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Linux">xsync /etc/profile.d/my_env.sh #同步<br>source /etc/profile #执行同步后的文件，添加路径<br><br></code></pre></td></tr></table></figure><p>脚本代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs Shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span><br>if [ $# -lt 1 ]<br>then<br>    echo Not Enough Arguement!<br>    exit;<br>fi<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span><br>for host in zzyhadoop02 zzyhadoop03 zzyhadoop04<br>do<br>    echo ====================  $host  ====================<br>    #3. 遍历所有目录，挨个发送<br><br>    for file in $@<br>    do<br>        #4. 判断文件是否存在<br>        if [ -e $file ]<br>            then<br>                #5. 获取父目录<br>                pdir=$(cd -P $(dirname $file); pwd)<br><br>                #6. 获取当前文件的名称<br>                fname=$(basename $file)<br>                ssh $host &quot;mkdir -p $pdir&quot;<br>                rsync -av $pdir/$fname $host:$pdir<br>            else<br>                echo $file does not exists!<br>        fi<br>    done<br>done<br><br></code></pre></td></tr></table></figure><p>免密登陆，方便传输配置文件。</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141013266.png" alt="免密登陆原理"></p><h2 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h2><p>NameNode和SecondaryNameNode不要安装在同一台服务器<br>ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p><p>配置要求如下。</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014550.png" alt="配置要求"></p><p>自定义配置文件：<br>    core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME&#x2F;etc&#x2F;hadoop这个路径上，根据项目需求重新进行修改配置。</p><p>02号机配置完成后，配置workers，内容为三台机器的名称。最后运行xsync脚本分发给其他机器。</p><h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><p><strong>集群是第一次启动</strong>，需要在zzyhadoop02节点格式化NameNode.</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">##zzyhadoop02节点<br>hdfs namenode -format ##格式化NameNode<br>sbin/start-dfs.sh ##启动HDFS<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014925.png" alt="节点启动成功"></p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014755.png" alt="版本号"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">##zzyhadoop03节点（配置了ResourceManager的节点）启动YARN</span><br>sbin/start-yarn.sh<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014933.png" alt="启动YARN"></p><p>接下来可以在Web端查看HDFS的NameNode。</p><p>浏览器中输入：zzyhadoop02:9870即可查看HDFS上存储的数据信息</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014134.png" alt="网站"></p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014724.png" alt="YARN运行情况"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>先配置虚拟机，到下载JDK和Hadoop，配置集群，最后启动。整体过程相对顺利，对Hadoop框架的三大内容HDFS（分布式文件系统）、YARN（计算资源管理）和MapReduce（计算引擎）有了更新的认识。接下来对YARN和MapReduce的学习不可或缺。为了方便后续的学习，再配置一下历史服务器和日志的聚集，向MR编程进发！</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>学习使用Apache Hive</title>
    <link href="/2024/05/08/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8Apache-Hive/"/>
    <url>/2024/05/08/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8Apache-Hive/</url>
    
    <content type="html"><![CDATA[<h2 id="HIVE的作用"><a href="#HIVE的作用" class="headerlink" title="HIVE的作用"></a>HIVE的作用</h2><p>将数据文件<strong>映射</strong>为一张表。<br>将SQL语法解析编译成为MapReduce的执行程序。</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091105876.png" alt="Hive架构"></p><h2 id="HIVE的组件"><a href="#HIVE的组件" class="headerlink" title="HIVE的组件"></a>HIVE的组件</h2><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106014.png" alt="Hive组件"></p><p><strong>1.用户接口</strong></p><p>包括CLI，JDBC&#x2F;ODBC、WebGUI。<br>CLI(Command Line Interface)即命令行，是Hive的默认模式。<br>HIVE中的Thrift服务器允许外部客户端通过网络与Hive交互，类似于JDBC或ODBC协议。（JDBC&#x2F;ODBC即Java数据库连接，是Hive的默认模式。<br>WebGUI是Hive的Web界面，提供给用户友好的操作界面。</p><p><strong>2.元数据存储</strong><br>通常是存储在关系数据库如MySQL、Postgresql等。</p><p><strong>3.解释器</strong><br>将SQL转换为MapReduce任务，最后提交给Hadoop执行。</p><p><strong>4.编译器</strong><br>将SQL编译成可以运行的MapReduce程序。</p><p><strong>5.优化器</strong><br>优化MR程序，转换为执行效率更高的执行计划。</p><p><strong>6.执行器</strong><br>提交MR程序给Hadoop执行，然后返回结果。HIVE支持Mapreduce、Tez和Spark三种执行引擎。</p><h2 id="Hive数据模型"><a href="#Hive数据模型" class="headerlink" title="Hive数据模型"></a>Hive数据模型</h2><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106540.png" alt="文件位置关系"><br>HIVE中的数据模型分为三层：<br><strong>1.元数据</strong><br>元数据存储在关系数据库中，如MySQL、Postgresql等。<br><strong>2.内部表</strong><br>内部表是Hive默认的表类型，数据存储在HDFS中。<br><strong>3.外部表</strong><br>外部表是用户自定义的表类型，数据存储在HDFS中，但元数据存储在Hive的元数据存储中。<br><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106810.png" alt="Hive与数据库的区别"></p><h2 id="Hive-Metadata"><a href="#Hive-Metadata" class="headerlink" title="Hive Metadata"></a>Hive Metadata</h2><p>Hive Metadata存储在关系数据库中，如MySQL、Postgresql等。<br>Hive Metadata存储了Hive 创建的database、表及其位置、类型、字段顺序等。</p><h2 id="Hive-Metastore"><a href="#Hive-Metastore" class="headerlink" title="Hive Metastore"></a>Hive Metastore</h2><p>元数据服务，作用是管理Hive Metadata。对外暴露服务地址，让各种客户端通过连接Metastore服务，由Metastore再去连接数据库存取元数据。<br>好处：多个客户可同时连接；客户不知道数据库账号密码，保证元数据安全。</p><h2 id="Metastore的配置方式"><a href="#Metastore的配置方式" class="headerlink" title="Metastore的配置方式"></a>Metastore的配置方式</h2><p>内嵌模式、本地模式、远程模式。<br>区分方式：<br>1.是否需要启动Metastore服务？<br>2.Metadata是存储在内置的数据库（如Derby）中还是远程数据库(如MySQL、Postgresql)中？</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106614.png" alt="模式区分判断依据"></p><h2 id="未完待续…"><a href="#未完待续…" class="headerlink" title="未完待续…."></a>未完待续….</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>数仓是什么？</title>
    <link href="/2024/05/06/%E6%95%B0%E4%BB%93%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <url>/2024/05/06/%E6%95%B0%E4%BB%93%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="数仓是什么？为了分析数据！"><a href="#数仓是什么？为了分析数据！" class="headerlink" title="数仓是什么？为了分析数据！"></a>数仓是什么？为了分析数据！</h2><p>数仓（Data Warehouse）是数据仓库的简称，是一种<strong>面向主题的、集成的、时变的、非易失的数据集合</strong>，用于支持管理决策。</p><p>数仓通常由数据仓库、数据集市和数据湖等组件组成，它们共同构成了一个完整的数据架构。数据仓库用于存储和分析历史数据，数据集市用于存储和分析特定主题的数据，数据湖则用于存储和分析所有类型的数据。</p><p>数仓的目的是提供一种统一的数据访问方式，使得企业能够方便地获取所需的数据，并进行分析和决策。</p><p>数仓通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据，同时也支持使用Hadoop等大数据技术来处理和分析数据。</p><p>数仓的构建和维护需要使用相应的工具和平台，如ETL工具（如Sqoop、Kettle等）来提取、转换和加载数据，数据仓库管理和分析平台（如Hive、Impala等）来管理和分析数据。</p><p>数仓的构建和维护需要遵循一定的规范和标准，如数据模型、数据格式、数据质量等。</p><p>数仓的构建和维护需要使用相应的工具和平台，如ETL工具（如Sqoop、Kettle等）来提取、转换和加载数据，数据仓库管理和分析平台（如Hive、Impala等）来管理和分析数据。</p><p>数仓的构建和维护需要遵循一定的规范和标准，如数据模型、数据格式、数据质量等。</p><h2 id="为什么要数仓？"><a href="#为什么要数仓？" class="headerlink" title="为什么要数仓？"></a>为什么要数仓？</h2><p>在哪里进行数据分析？数据库？<br>业务操作分为读操作和写操作，但是<strong>读操作</strong>&#x3D;&#x3D;的压力大于写操作。<br><strong>目的：数据分析与业务解耦合，分析支持决策但不影响业务。</strong><br>OLTP（On-Line Transaction Processing）：联机事务处理，面向业务操作，对事务的响应时间有要求，对数据的实时性要求较高。<br>举例：针对具体业务再数据库联机的日常操作，对少量数据的增删改查。关系型数据库作为数据管理的主要手段。</p><p>OLAP（On-Line Analytical）：联机分析处理，面向数据分析，对事务的响应时间没有要求，对数据的实时性要求较低。<br>举例：针对某些主题的历史数据进行复杂的多维分析。数据仓库是OLAP系统的典型事例。</p><h2 id="数仓分层架构"><a href="#数仓分层架构" class="headerlink" title="数仓分层架构"></a>数仓分层架构</h2><p>操作型数据层（ODS）、数据仓库层（DW）、数据集市层（DM）、数据应用层（DA）。</p><p>ODS：操作型数据层，用于存储原始数据，通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据。</p><p>DW：数据仓库层，用于存储经过清洗、转换和整合后的数据，通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据。</p><p>DM：数据集市层，用于存储特定主题的数据，通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据。</p><p>DA：数据应用层，用于提供数据分析和决策支持，通常采用数据仓库管理和分析平台（如Hive、Impala等）来管理和分析数据。</p><p><strong>分层的好处是：清洗数据结构、数据血缘追踪、减少重复开发（如查询接口）、屏蔽原始数据的异常</strong></p><h2 id="ETL和ELT"><a href="#ETL和ELT" class="headerlink" title="ETL和ELT"></a>ETL和ELT</h2><p>ETL（Extract-Transform-Load）：提取、转换和加载，用于将数据从源系统提取出来，经过清洗、转换和整合后加载到目标系统。</p><p>ELT（Extract-Load-Transform）：提取、加载和转换，用于将数据从源系统提取出来，直接加载到目标系统，然后再进行转换。</p><h2 id="数仓的构建"><a href="#数仓的构建" class="headerlink" title="数仓的构建"></a>数仓的构建</h2><ol><li>数据收集：从业务系统中收集数据，包括原始数据和业务日志。</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>网络和操作系统基础</title>
    <link href="/2024/04/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <url>/2024/04/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h1><h2 id="三次握手过程"><a href="#三次握手过程" class="headerlink" title="三次握手过程"></a>三次握手过程</h2><p>客户端——发送带有SYN标志的数据包——服务端一次握手Client进入syn_sent状态；<br>服务端——发送带有SYN&#x2F;ACK标志的数据包——客户端二次握手服务端进入syn_rcvd；<br>客户端——发送带有ACK标志的数据包——服务端三次握手连接就进入Established状态；</p><h2 id="为什么三次："><a href="#为什么三次：" class="headerlink" title="为什么三次："></a>为什么三次：</h2><p>主要是为了建立可靠的通信信道，保证客户端与服务端同时具备发送、接收数据的能力。</p><h2 id="为什么两次不行："><a href="#为什么两次不行：" class="headerlink" title="为什么两次不行："></a>为什么两次不行：</h2><p>1、防止已失效的请求报文又传送到了服务端，建立了多余的链接，浪费资源。</p><p>2、两次握手只能保证单向连接是畅通的。（为了实现可靠数据传输，TCP协议的通信双方，都必须维护一个序列号，以标识发送出去的数据包中，哪些是已经被对方收到的。三次握手的过程即是通信双方相互告知序列号起始值，并确认对方已经收到了序列号起始值的必经步骤；如果只是两次握手，至多只有连接发起方的起始序列号能被确认，另一方选择的序列号则得不到确认）。</p><h1 id="TCP四次挥手过程"><a href="#TCP四次挥手过程" class="headerlink" title="TCP四次挥手过程"></a>TCP四次挥手过程</h1><h2 id="四次挥手过程："><a href="#四次挥手过程：" class="headerlink" title="四次挥手过程："></a>四次挥手过程：</h2><p>客户端——发送带有FIN标志的数据包——服务端，关闭与服务端的连接，客户端进入FIN-WAIT-1状态。</p><p>服务端收到这个FIN，它发回⼀个ACK，确认序号为收到的序号加1，服务端就进入了CLOSE-WAIT状态。</p><p>服务端——发送⼀个FIN数据包——客户端，关闭与客户端的连接，客户端就进入FIN-WAIT-2状态。</p><p>客户端收到这个FIN，发回ACK报⽂确认，并将确认序号设置为收到序号加1，TIME-WAIT状态。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
