<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MapReduce框架原理</title>
    <link href="/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/"/>
    <url>/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="MapReduce框架原理"><a href="#MapReduce框架原理" class="headerlink" title="MapReduce框架原理"></a>MapReduce框架原理</h2><img src="/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/框架.png" alt="框架" style="zoom:80%;"><h3 id="切片与MapTask并行度决定机制"><a href="#切片与MapTask并行度决定机制" class="headerlink" title="切片与MapTask并行度决定机制"></a>切片与MapTask并行度决定机制</h3><p><strong>数据块：</strong>Block是HDFS物理上把数据分成一块一块。数据块是HDFS存储数据单位。</p><p><strong>数据切片：</strong>数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask。</p><p>1）一个Job的Map阶段并行度由客户端在提交Job时的切片数决定</p><p>2）每一个Split切片分配一个MapTask并行实例处理</p><p>3）默认情况下，切片大小&#x3D;BlockSize</p><p>4)切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p><h3 id="Job提交流程源码解析"><a href="#Job提交流程源码解析" class="headerlink" title="Job提交流程源码解析"></a>Job提交流程源码解析</h3><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs stata">waitForCompletion()<br><br>submit();<br><br><span class="hljs-comment">// 1建立连接</span><br>connect();<br><span class="hljs-comment">// 1）创建提交Job的代理</span><br>new <span class="hljs-keyword">Cluster</span>(getConfiguration());<br><span class="hljs-comment">// （1）判断是本地运行环境还是yarn集群运行环境</span><br>initialize(jobTrackAddr, <span class="hljs-keyword">conf</span>); <br><br><span class="hljs-comment">// 2 提交job</span><br>submitter.submitJobInternal(Job.this, <span class="hljs-keyword">cluster</span>)<br><br><span class="hljs-comment">// 1）创建给集群提交数据的Stag路径</span><br>Path jobStagingArea = JobSubmissionFiles.getStagingDir(<span class="hljs-keyword">cluster</span>, <span class="hljs-keyword">conf</span>);<br><br><span class="hljs-comment">// 2）获取jobid ，并创建Job路径</span><br>JobID jobId = submitClient.getNewJobID();<br><br><span class="hljs-comment">// 3）拷贝jar包到集群</span><br>copyAndConfigureFiles(job, submitJobDir);<br>rUploader.uploadFiles(job, jobSubmitDir);<br><br><span class="hljs-comment">// 4）计算切片，生成切片规划文件</span><br>writeSplits(job, submitJobDir);<br>maps = writeNewSplits(job, jobSubmitDir);<br><span class="hljs-keyword">input</span>.getSplits(job);<br><br><span class="hljs-comment">// 5）向Stag路径写XML配置文件</span><br>writeConf(<span class="hljs-keyword">conf</span>, submitJobFile);<br><span class="hljs-keyword">conf</span>.writeXml(<span class="hljs-keyword">out</span>);<br><br><span class="hljs-comment">// 6）提交Job,返回提交状态</span><br>status = submitClient.submitJob(jobId, submitJobDir.<span class="hljs-keyword">toString</span>(), job.getCredentials());<br><br></code></pre></td></tr></table></figure><p><img src="/2024/05/27/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B.png" alt="Job提交流程"></p><p>在运行MapReduce程序时，输入的文件格式包括：基于行的日志文件、二进制格式文件、数据库表等。那么，针对不同的数据类型FileInputFormat常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat和自定义InputFormat等。</p><p>TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量， LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符），Text类型。</p><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。</p><p>CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p><p>生成切片过程包括：虚拟存储过程和切片过程两部分。</p><p>（1）虚拟存储过程：</p><p>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</p><p>（2）切片过程：</p><p>（a）判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。</p><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p><p>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：</p><p>1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）</p><p>最终会形成3个切片，大小分别为：（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop的计算执行模块MapReduce</title>
    <link href="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/"/>
    <url>/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/</url>
    
    <content type="html"><![CDATA[<h2 id="MapReduce定义"><a href="#MapReduce定义" class="headerlink" title="MapReduce定义"></a>MapReduce定义</h2><p>MapReduce是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。</p><p>MapReduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个Hadoop集群上。</p><p><strong>优点：</strong></p><p>1.MapReduce易于编程</p><p>2.良好的扩展性</p><p>3.高容错性</p><p>4.适合PB级以上海量数据的离线处理</p><p><strong>缺点：</strong></p><p>1.不擅长实时计算</p><p>2.不擅长流式计算<del>（Sparkstreaming、Flink）</del></p><p>3.不擅长DAG（有向无环图）计算<del>（Spark）</del></p><h2 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h2><p><img src="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/MR%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3.png" alt="MR核心思想"></p><p><img src="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/mapper%E9%98%B6%E6%AE%B5.png" alt="mapper阶段"></p><p><img src="/2024/05/21/Hadoop%E7%9A%84%E8%AE%A1%E7%AE%97%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97MapReduce/reduce%E9%98%B6%E6%AE%B5.png" alt="reduce阶段"></p><p>一个完整的MapReduce程序在分布式运行时有三类实例进程：</p><p>（1）<strong>MrAppMaster</strong>：负责整个程序的过程调度及状态协调。</p><p>（2）<strong>MapTask</strong>：负责Map阶段的整个数据处理流程。</p><p>（3）<strong>ReduceTask</strong>：负责Reduce阶段的整个数据处理流程。</p><h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>1）<strong>什么是序列化</strong></p><p><strong>序列化</strong>就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。 </p><p><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。</p><p>2）<strong>为什么要序列化</strong></p><p>一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</p><p>3）为什么不用Java的序列化</p><p>Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop自己开发了一套序列化机制（Writable）。</p><p>4）Hadoop序列化特点：</p><p>（1）<strong>紧凑</strong> <strong>：</strong>高效使用存储空间。</p><p>（2）<strong>快速：</strong>读写数据的额外开销小。</p><p>（3）<strong>互操作：</strong>支持多语言的交互.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop之HDFS</title>
    <link href="/2024/05/16/Hadoop%E4%B9%8BHDFS/"/>
    <url>/2024/05/16/Hadoop%E4%B9%8BHDFS/</url>
    
    <content type="html"><![CDATA[<h1 id="Hadoop三大件之Hive"><a href="#Hadoop三大件之Hive" class="headerlink" title="Hadoop三大件之Hive"></a>Hadoop三大件之Hive</h1><h2 id="HDFS的背景和意义"><a href="#HDFS的背景和意义" class="headerlink" title="HDFS的背景和意义"></a>HDFS的背景和意义</h2><p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。<strong>HDFS（Hadoop Distributed File System）只是分布式文件管理系统中的一种。</strong>其他还有诸如 <strong>Amazon S3 (Simple Storage Service)<strong>、</strong>Google Cloud Storage</strong>、<strong>Microsoft Azure Blob Storage</strong>等。</p><p>HDFS（Hadoop Distributed File System），用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p><p>HDFS的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭之后就不需要改变。</p><h2 id="HDFS的优缺点"><a href="#HDFS的优缺点" class="headerlink" title="HDFS的优缺点"></a>HDFS的优缺点</h2><p>优点：</p><p>1.高容错性：数据自动保存多个副本</p><p>2.大数据处理：数据规模大，能达到TB甚至PB级别的数据；文件规模大，能达到百万文件数量。</p><p>3.可靠性和经济性：可构建在普通计算机上，通过多副本机制提高可靠性。</p><p>缺点：</p><p>1.无法做到低延时数据访问。</p><p>2.无法高效对大量小文件存储。</p><p>3.不支持并发写入、文件随机修改。（仅支持数据append）</p><h2 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h2><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405201620844.png" alt="hdfs组成架构"></p><p><strong>NameNode（NN）：</strong></p><p>（1）管理HDFS的名称空间；</p><p>（2）配置副本策略；</p><p>（3）管理数据块（Block）映射信息；</p><p>（4）处理客户端读写请求。</p><p><strong>DataNode：</strong></p><p>（1）存储实际的数据块；</p><p>（2）执行数据块的读写操作。</p><p><strong>Client：</strong></p><p>（1）文件切分，文件上传后被切分为Block，然后进行上传。</p><p>（2）与NameNode交互，获取文件的位置信息。</p><p>（3）与DataNode交互，读取或写入数据。</p><p>（4）提供一些命令来管理HDFS，比如NN的格式化和访问HDFS。</p><p><strong>Secondary NameNode：</strong></p><p>（1）辅助NameNode，分担其工作量。（比如定期合并Fsimage和Edits,并推给NN）</p><p>（2）紧急情况下，可辅助恢复NameNode。</p><p>文件块（Block）：HDFS中的文件在物理上是分块存储，大小一般为128或256M。与磁盘传输速率相关。</p><h2 id="HDFS的Shell命令"><a href="#HDFS的Shell命令" class="headerlink" title="HDFS的Shell命令"></a>HDFS的Shell命令</h2><p><strong>上传命令：</strong></p><p>-moveFromLocal：从本地剪切粘贴到HDFS</p><p>-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><p>-put：等同于copyFromLocal，生产环境更习惯用put</p><p>-appendToFile：追加一个文件到已经存在的文件末尾</p><p><strong>下载命令：</strong></p><p>-copyToLocal：从HDFS拷贝到本地</p><p>-get：等同于copyToLocal，生产环境更习惯用get</p><h2 id="HDFS的写数据流程"><a href="#HDFS的写数据流程" class="headerlink" title="HDFS的写数据流程"></a>HDFS的写数据流程</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png" alt="写数据流程"></p><p>（1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p><p>（2）NameNode返回是否可以上传。</p><p>（3）客户端请求第一个 Block上传到哪几个DataNode服务器上。</p><p>（4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。</p><p>（5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p><p>（6）dn1、dn2、dn3逐级应答客户端。</p><p>（7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</p><p>（8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p><p><strong>副本节点选择</strong></p><p>第一个副本在Client所处的节点上。如果客户端在集群外，随机选一个。</p><p>第二个副本在另一个机架的随机一个节点。</p><p>第三个副本在第二个副本所在机架的随机节点。</p><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9.png" alt="副本存储节点选择"></p><h2 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png" alt="读数据流程"></p><p>（1）客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p><p>（2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</p><p>（3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</p><p>（4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</p><h2 id="NameNode工作机制"><a href="#NameNode工作机制" class="headerlink" title="NameNode工作机制"></a>NameNode工作机制</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/nn%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png" alt="nn工作机制"></p><p>1）第一阶段：NameNode启动</p><p>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p><p>（2）客户端对元数据进行增删改的请求。</p><p>（3）NameNode记录操作日志，更新滚动日志。</p><p>（4）NameNode在内存中对元数据进行增删改。</p><p>2）第二阶段：Secondary NameNode工作</p><p>（1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</p><p>（2）Secondary NameNode请求执行CheckPoint。</p><p>（3）NameNode滚动正在写的Edits日志。</p><p>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</p><p>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p><p>（6）生成新的镜像文件fsimage.chkpoint。</p><p>（7）拷贝fsimage.chkpoint到NameNode。</p><p>（8）NameNode将fsimage.chkpoint重新命名成fsimage。</p><h2 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h2><p><img src="/2024/05/16/Hadoop%E4%B9%8BHDFS/DN%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="DN工作流程"></p><p>（1）一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</p><p>（2）DataNode启动后向NameNode注册，通过后，周期性（6小时）的向NameNode上报所有的块信息。</p><p>DN向NN汇报当前解读信息的时间间隔，默认6小时。</p><p>（3）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</p><p>（4）集群运行中可以安全加入和退出一些机器。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>针对HDFS的学习集中在各个组成部分的工作机制，而对里面的细节没有深入，比如Fsimage和Edits的解析。后续在生产环境再深入学习吧。HDFS组成部分间的成员角色和工作流程诠释了分布式文件系统分块存储的特点，同时兼顾传输效率和可靠性！</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop搭建完全分布式运行模式</title>
    <link href="/2024/05/11/Hadoop%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    <url>/2024/05/11/Hadoop%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="Hadoop搭建之完全分布式运行模式"><a href="#Hadoop搭建之完全分布式运行模式" class="headerlink" title="Hadoop搭建之完全分布式运行模式"></a>Hadoop搭建之完全分布式运行模式</h1><h2 id="起因："><a href="#起因：" class="headerlink" title="起因："></a>起因：</h2><p>课题组的服务器的大数据集群是好几年前的师兄们安装配置，并由星环公司提供技术服务，因此对基本的大数据环境搭建并不熟悉。这篇文章就是记录从头开始搭建Hadoop的生产环境，并记录遇到的问题和解决过程。</p><h2 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a>准备工作：</h2><p>1.四台虚拟机zzyhadoop01\02\03\04，系统CentOS7，配置好IP</p><p>2.JDK和Hadoop的软件包</p><p>3.Linux远程连接工具Xshell和文件传输工具Xftp</p><h2 id="配置开始："><a href="#配置开始：" class="headerlink" title="配置开始："></a>配置开始：</h2><p>02号机已经安装好JDK和Hadoop，使用scp（secure copy，安全拷贝）将JDK和Hadoop复制到03、04号机上。</p><figure class="highlight plaintext"><figcaption><span>命令</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Linux">[root@zzyhadoop02 ~]# scp -r /opt/module/jdk1.8.0_212 root@zzyhadoop03:/opt/module<br>[root@zzyhadoop03 ~]# scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/<br>[root@zzyhadoop03 ~]# scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module<br>##上述所在主机不同，要分清从哪里拿文件，送到哪里去<br>## scp    -r        $pdir/$fname             $user@$host:$pdir/$fname<br>## 命令   递归     要拷贝的文件路径/名称   目的地用户@主机:目的地路径/名称<br><br></code></pre></td></tr></table></figure><p><strong>rsync远程同步工具</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">rsync</span>   -av    <span class="hljs-variable">$pdir</span>/<span class="hljs-variable">$fname</span>       <span class="hljs-variable">$user</span>@<span class="hljs-variable">$host</span>:<span class="hljs-variable">$pdir</span>/<span class="hljs-variable">$fname</span><br><span class="hljs-comment">## -a 归档拷贝 -v 显示复制过程</span><br><span class="hljs-comment">##命令  选项参数  要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称</span><br></code></pre></td></tr></table></figure><p>同步环境变量到03、04</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Linux">xsync /etc/profile.d/my_env.sh #同步<br>source /etc/profile #执行同步后的文件，添加路径<br><br></code></pre></td></tr></table></figure><p>脚本代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs Shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span><br>if [ $# -lt 1 ]<br>then<br>    echo Not Enough Arguement!<br>    exit;<br>fi<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span><br>for host in zzyhadoop02 zzyhadoop03 zzyhadoop04<br>do<br>    echo ====================  $host  ====================<br>    #3. 遍历所有目录，挨个发送<br><br>    for file in $@<br>    do<br>        #4. 判断文件是否存在<br>        if [ -e $file ]<br>            then<br>                #5. 获取父目录<br>                pdir=$(cd -P $(dirname $file); pwd)<br><br>                #6. 获取当前文件的名称<br>                fname=$(basename $file)<br>                ssh $host &quot;mkdir -p $pdir&quot;<br>                rsync -av $pdir/$fname $host:$pdir<br>            else<br>                echo $file does not exists!<br>        fi<br>    done<br>done<br><br></code></pre></td></tr></table></figure><p>免密登陆，方便传输配置文件。</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141013266.png" alt="免密登陆原理"></p><h2 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h2><p>NameNode和SecondaryNameNode不要安装在同一台服务器<br>ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p><p>配置要求如下。</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014550.png" alt="配置要求"></p><p>自定义配置文件：<br>    core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME&#x2F;etc&#x2F;hadoop这个路径上，根据项目需求重新进行修改配置。</p><p>02号机配置完成后，配置workers，内容为三台机器的名称。最后运行xsync脚本分发给其他机器。</p><h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><p><strong>集群是第一次启动</strong>，需要在zzyhadoop02节点格式化NameNode.</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">##zzyhadoop02节点<br>hdfs namenode -format ##格式化NameNode<br>sbin/start-dfs.sh ##启动HDFS<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014925.png" alt="节点启动成功"></p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014755.png" alt="版本号"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">##zzyhadoop03节点（配置了ResourceManager的节点）启动YARN</span><br>sbin/start-yarn.sh<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014933.png" alt="启动YARN"></p><p>接下来可以在Web端查看HDFS的NameNode。</p><p>浏览器中输入：zzyhadoop02:9870即可查看HDFS上存储的数据信息</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014134.png" alt="网站"></p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hadoop_photo202405141014724.png" alt="YARN运行情况"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>先配置虚拟机，到下载JDK和Hadoop，配置集群，最后启动。整体过程相对顺利，对Hadoop框架的三大内容HDFS（分布式文件系统）、YARN（计算资源管理）和MapReduce（计算引擎）有了更新的认识。接下来对YARN和MapReduce的学习不可或缺。为了方便后续的学习，再配置一下历史服务器和日志的聚集，向MR编程进发！</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>学习使用Apache Hive</title>
    <link href="/2024/05/08/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8Apache-Hive/"/>
    <url>/2024/05/08/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8Apache-Hive/</url>
    
    <content type="html"><![CDATA[<h2 id="HIVE的作用"><a href="#HIVE的作用" class="headerlink" title="HIVE的作用"></a>HIVE的作用</h2><p>将数据文件<strong>映射</strong>为一张表。<br>将SQL语法解析编译成为MapReduce的执行程序。</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091105876.png" alt="Hive架构"></p><h2 id="HIVE的组件"><a href="#HIVE的组件" class="headerlink" title="HIVE的组件"></a>HIVE的组件</h2><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106014.png" alt="Hive组件"></p><p><strong>1.用户接口</strong></p><p>包括CLI，JDBC&#x2F;ODBC、WebGUI。<br>CLI(Command Line Interface)即命令行，是Hive的默认模式。<br>HIVE中的Thrift服务器允许外部客户端通过网络与Hive交互，类似于JDBC或ODBC协议。（JDBC&#x2F;ODBC即Java数据库连接，是Hive的默认模式。<br>WebGUI是Hive的Web界面，提供给用户友好的操作界面。</p><p><strong>2.元数据存储</strong><br>通常是存储在关系数据库如MySQL、Postgresql等。</p><p><strong>3.解释器</strong><br>将SQL转换为MapReduce任务，最后提交给Hadoop执行。</p><p><strong>4.编译器</strong><br>将SQL编译成可以运行的MapReduce程序。</p><p><strong>5.优化器</strong><br>优化MR程序，转换为执行效率更高的执行计划。</p><p><strong>6.执行器</strong><br>提交MR程序给Hadoop执行，然后返回结果。HIVE支持Mapreduce、Tez和Spark三种执行引擎。</p><h2 id="Hive数据模型"><a href="#Hive数据模型" class="headerlink" title="Hive数据模型"></a>Hive数据模型</h2><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106540.png" alt="文件位置关系"><br>HIVE中的数据模型分为三层：<br><strong>1.元数据</strong><br>元数据存储在关系数据库中，如MySQL、Postgresql等。<br><strong>2.内部表</strong><br>内部表是Hive默认的表类型，数据存储在HDFS中。<br><strong>3.外部表</strong><br>外部表是用户自定义的表类型，数据存储在HDFS中，但元数据存储在Hive的元数据存储中。<br><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106810.png" alt="Hive与数据库的区别"></p><h2 id="Hive-Metadata"><a href="#Hive-Metadata" class="headerlink" title="Hive Metadata"></a>Hive Metadata</h2><p>Hive Metadata存储在关系数据库中，如MySQL、Postgresql等。<br>Hive Metadata存储了Hive 创建的database、表及其位置、类型、字段顺序等。</p><h2 id="Hive-Metastore"><a href="#Hive-Metastore" class="headerlink" title="Hive Metastore"></a>Hive Metastore</h2><p>元数据服务，作用是管理Hive Metadata。对外暴露服务地址，让各种客户端通过连接Metastore服务，由Metastore再去连接数据库存取元数据。<br>好处：多个客户可同时连接；客户不知道数据库账号密码，保证元数据安全。</p><h2 id="Metastore的配置方式"><a href="#Metastore的配置方式" class="headerlink" title="Metastore的配置方式"></a>Metastore的配置方式</h2><p>内嵌模式、本地模式、远程模式。<br>区分方式：<br>1.是否需要启动Metastore服务？<br>2.Metadata是存储在内置的数据库（如Derby）中还是远程数据库(如MySQL、Postgresql)中？</p><p><img src="https://cdn.jsdelivr.net/gh/zzy-1128/photohouse/hexo/hive_photo202405091106614.png" alt="模式区分判断依据"></p><h2 id="未完待续…"><a href="#未完待续…" class="headerlink" title="未完待续…."></a>未完待续….</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>数仓是什么？</title>
    <link href="/2024/05/06/%E6%95%B0%E4%BB%93%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <url>/2024/05/06/%E6%95%B0%E4%BB%93%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="数仓是什么？为了分析数据！"><a href="#数仓是什么？为了分析数据！" class="headerlink" title="数仓是什么？为了分析数据！"></a>数仓是什么？为了分析数据！</h2><p>数仓（Data Warehouse）是数据仓库的简称，是一种<strong>面向主题的、集成的、时变的、非易失的数据集合</strong>，用于支持管理决策。</p><p>数仓通常由数据仓库、数据集市和数据湖等组件组成，它们共同构成了一个完整的数据架构。数据仓库用于存储和分析历史数据，数据集市用于存储和分析特定主题的数据，数据湖则用于存储和分析所有类型的数据。</p><p>数仓的目的是提供一种统一的数据访问方式，使得企业能够方便地获取所需的数据，并进行分析和决策。</p><p>数仓通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据，同时也支持使用Hadoop等大数据技术来处理和分析数据。</p><p>数仓的构建和维护需要使用相应的工具和平台，如ETL工具（如Sqoop、Kettle等）来提取、转换和加载数据，数据仓库管理和分析平台（如Hive、Impala等）来管理和分析数据。</p><p>数仓的构建和维护需要遵循一定的规范和标准，如数据模型、数据格式、数据质量等。</p><p>数仓的构建和维护需要使用相应的工具和平台，如ETL工具（如Sqoop、Kettle等）来提取、转换和加载数据，数据仓库管理和分析平台（如Hive、Impala等）来管理和分析数据。</p><p>数仓的构建和维护需要遵循一定的规范和标准，如数据模型、数据格式、数据质量等。</p><h2 id="为什么要数仓？"><a href="#为什么要数仓？" class="headerlink" title="为什么要数仓？"></a>为什么要数仓？</h2><p>在哪里进行数据分析？数据库？<br>业务操作分为读操作和写操作，但是<strong>读操作</strong>&#x3D;&#x3D;的压力大于写操作。<br><strong>目的：数据分析与业务解耦合，分析支持决策但不影响业务。</strong><br>OLTP（On-Line Transaction Processing）：联机事务处理，面向业务操作，对事务的响应时间有要求，对数据的实时性要求较高。<br>举例：针对具体业务再数据库联机的日常操作，对少量数据的增删改查。关系型数据库作为数据管理的主要手段。</p><p>OLAP（On-Line Analytical）：联机分析处理，面向数据分析，对事务的响应时间没有要求，对数据的实时性要求较低。<br>举例：针对某些主题的历史数据进行复杂的多维分析。数据仓库是OLAP系统的典型事例。</p><h2 id="数仓分层架构"><a href="#数仓分层架构" class="headerlink" title="数仓分层架构"></a>数仓分层架构</h2><p>操作型数据层（ODS）、数据仓库层（DW）、数据集市层（DM）、数据应用层（DA）。</p><p>ODS：操作型数据层，用于存储原始数据，通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据。</p><p>DW：数据仓库层，用于存储经过清洗、转换和整合后的数据，通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据。</p><p>DM：数据集市层，用于存储特定主题的数据，通常采用关系型数据库（如Oracle、SQL Server等）来存储和管理数据。</p><p>DA：数据应用层，用于提供数据分析和决策支持，通常采用数据仓库管理和分析平台（如Hive、Impala等）来管理和分析数据。</p><p><strong>分层的好处是：清洗数据结构、数据血缘追踪、减少重复开发（如查询接口）、屏蔽原始数据的异常</strong></p><h2 id="ETL和ELT"><a href="#ETL和ELT" class="headerlink" title="ETL和ELT"></a>ETL和ELT</h2><p>ETL（Extract-Transform-Load）：提取、转换和加载，用于将数据从源系统提取出来，经过清洗、转换和整合后加载到目标系统。</p><p>ELT（Extract-Load-Transform）：提取、加载和转换，用于将数据从源系统提取出来，直接加载到目标系统，然后再进行转换。</p><h2 id="数仓的构建"><a href="#数仓的构建" class="headerlink" title="数仓的构建"></a>数仓的构建</h2><ol><li>数据收集：从业务系统中收集数据，包括原始数据和业务日志。</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>网络和操作系统基础</title>
    <link href="/2024/04/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <url>/2024/04/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h1><h2 id="三次握手过程"><a href="#三次握手过程" class="headerlink" title="三次握手过程"></a>三次握手过程</h2><p>客户端——发送带有SYN标志的数据包——服务端一次握手Client进入syn_sent状态；<br>服务端——发送带有SYN&#x2F;ACK标志的数据包——客户端二次握手服务端进入syn_rcvd；<br>客户端——发送带有ACK标志的数据包——服务端三次握手连接就进入Established状态；</p><h2 id="为什么三次："><a href="#为什么三次：" class="headerlink" title="为什么三次："></a>为什么三次：</h2><p>主要是为了建立可靠的通信信道，保证客户端与服务端同时具备发送、接收数据的能力。</p><h2 id="为什么两次不行："><a href="#为什么两次不行：" class="headerlink" title="为什么两次不行："></a>为什么两次不行：</h2><p>1、防止已失效的请求报文又传送到了服务端，建立了多余的链接，浪费资源。</p><p>2、两次握手只能保证单向连接是畅通的。（为了实现可靠数据传输，TCP协议的通信双方，都必须维护一个序列号，以标识发送出去的数据包中，哪些是已经被对方收到的。三次握手的过程即是通信双方相互告知序列号起始值，并确认对方已经收到了序列号起始值的必经步骤；如果只是两次握手，至多只有连接发起方的起始序列号能被确认，另一方选择的序列号则得不到确认）。</p><h1 id="TCP四次挥手过程"><a href="#TCP四次挥手过程" class="headerlink" title="TCP四次挥手过程"></a>TCP四次挥手过程</h1><h2 id="四次挥手过程："><a href="#四次挥手过程：" class="headerlink" title="四次挥手过程："></a>四次挥手过程：</h2><p>客户端——发送带有FIN标志的数据包——服务端，关闭与服务端的连接，客户端进入FIN-WAIT-1状态。</p><p>服务端收到这个FIN，它发回⼀个ACK，确认序号为收到的序号加1，服务端就进入了CLOSE-WAIT状态。</p><p>服务端——发送⼀个FIN数据包——客户端，关闭与客户端的连接，客户端就进入FIN-WAIT-2状态。</p><p>客户端收到这个FIN，发回ACK报⽂确认，并将确认序号设置为收到序号加1，TIME-WAIT状态。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
